# app.py
import streamlit as st
from utils import PERSONA_NAMES
from rag_components import load_and_preprocess_data, get_retriever, create_agentic_rag_app, generate_suggested_questions

st.set_page_config(page_title="Data Persona Interativa - Tera", page_icon="üéì", layout="wide")

if 'screen' not in st.session_state: st.session_state.screen = 'home'
if 'messages' not in st.session_state: st.session_state.messages = []
if 'agentic_app' not in st.session_state: st.session_state.agentic_app = None

def render_footer():
    st.markdown("---")
    st.markdown("Desenvolvido por [Pedro Costa](https://www.linkedin.com/in/pedrocsta/) | Product Marketing & Martech Specialist")

def render_home_screen():
    st.title("Data Persona Interativa üéì")
    
    # NOVO TEXTO PARA A TERA
    st.markdown("""
    Esta aplica√ß√£o cria uma persona interativa e 100% data-driven, representando os alunos e profissionais que comp√µem o ecossistema da **Tera**. 
    Utilizando a arquitetura **RAG com Agentes de IA**, esta persona responde exclusivamente com base em uma base de conhecimento real (depoimentos, pesquisas, etc.), garantindo insights aut√™nticos.

    Seu verdadeiro poder √© a **autonomia** para os times da Tera. Em vez de iniciar um novo ciclo de pesquisa para cada d√∫vida, a equipe pode conversar diretamente com uma representa√ß√£o fiel de seus alunos para validar hip√≥teses sobre cursos, testar narrativas de marketing e aprofundar a empatia de forma √°gil.
    """)
    with st.expander("‚öôÔ∏è Conhe√ßa o maquin√°rio por tr√°s da m√°gica"):
        st.markdown("""
        - **Modelo de Linguagem (LLM):** `Google Gemini 1.5 Pro & Flash`
        - **Arquitetura:** `RAG com Agentes de IA (LangGraph)`
        - **Orquestra√ß√£o:** `LangChain`
        - **Interface e Aplica√ß√£o:** `Python + Streamlit`
        - **Base de Dados Vetorial:** `ChromaDB (in-memory)`
        """)
    st.divider()

    # NOVOS SELETORES
    st.selectbox('Selecione a Escola:', ('Tera',), help="Esta vers√£o √© focada na Tera.")
    selected_product = st.selectbox(
        'Selecione a √Årea de Estudo para a Persona:',
        ('Product Management', 'UX Design', 'Data Analytics')
    )

    if st.button("Iniciar Entrevista", type="primary"):
        if "GEMINI_API_KEY" not in st.secrets:
            st.error("Chave da API n√£o configurada.")
            st.stop()
        api_key = st.secrets["GEMINI_API_KEY"]
        with st.spinner("Preparando a persona e seus agentes..."):
            full_data = load_and_preprocess_data("data")
            if full_data.empty: st.error("Nenhum dado v√°lido na pasta 'data'."); st.stop()
            retriever = get_retriever(full_data, selected_product, api_key)
            if retriever is None: st.error(f"N√£o h√° dados para a √°rea de '{selected_product}'."); st.stop()
            st.session_state.agentic_app = create_agentic_rag_app(retriever, api_key)
            st.session_state.persona_name = PERSONA_NAMES[selected_product]
            st.session_state.product_name = selected_product
            st.session_state.suggested_questions = generate_suggested_questions(api_key, st.session_state.persona_name, selected_product)
            st.session_state.screen = 'chat'
            st.session_state.messages = []
            st.rerun()
    render_footer()

def handle_new_message(prompt):
    st.session_state.messages.append({"role": "user", "content": prompt})
    payload = {"question": prompt, "chat_history": st.session_state.messages[:-1], "product_name": st.session_state.product_name, "persona_name": st.session_state.persona_name}
    with st.chat_message("assistant"):
        with st.spinner("A equipe de agentes est√° pensando..."):
            final_state = st.session_state.agentic_app.invoke(payload)
            response_content = final_state.get('final_answer', "Desculpe, n√£o consegui processar uma resposta.")
            source_documents = final_state.get('documents', [])
            st.markdown(response_content)
            if source_documents:
                with st.expander("Ver fontes utilizadas"):
                    for doc in source_documents: st.info(doc.page_content)
    st.session_state.messages.append({"role": "assistant", "content": response_content, "sources": source_documents})

def render_chat_screen():
    st.title(f"Entrevistando: {st.session_state.persona_name}")
    st.markdown("Esta √© uma demonstra√ß√£o. Converse com a persona para extrair insights.")
    st.divider()

    # Exibe o hist√≥rico
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant" and "sources" in message and message["sources"]:
                with st.expander("Ver fontes utilizadas"):
                    for doc in message["sources"]: st.info(doc.page_content)

    # Input do chat
    if prompt := st.chat_input("Digite para conversar!"):
        handle_new_message(prompt)
        st.rerun()

    st.divider()
    if st.button("‚¨ÖÔ∏è Iniciar Nova Entrevista"):
        keys_to_clear = ['messages', 'agentic_app', 'persona_name', 'product_name', 'suggested_questions']
        for key in keys_to_clear:
            if key in st.session_state: del st.session_state[key]
        st.session_state.screen = 'home'
        st.rerun()
    render_footer()

# --- L√≥gica Principal ---
if st.session_state.screen == 'home':
    render_home_screen()
elif st.session_state.screen == 'chat':
    render_chat_screen()
